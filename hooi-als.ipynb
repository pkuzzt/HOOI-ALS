{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f5e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode-n matricization of a tensor\n",
    "import numpy as np\n",
    "\n",
    "def tenmat(A,n):\n",
    "    # A: the input tensor\n",
    "    # n: the index\n",
    "    N = A.ndim\n",
    "    sizeA = np.array(A.shape)\n",
    "    In = sizeA[n]\n",
    "    Jn = int(A.size / In)\n",
    "    \n",
    "    perm = np.array(n)\n",
    "    perm = np.append(perm,np.arange(n))\n",
    "    perm = np.append(perm,np.arange(n+1,N))\n",
    "    B = np.transpose(A,perm)\n",
    "    A_mat = np.reshape(B,[In,Jn])\n",
    "    \n",
    "    return A_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac9b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate a tensor times a matrix\n",
    "import numpy as np\n",
    "\n",
    "def ttm(A,U,n):\n",
    "    # A: the input tensor\n",
    "    # U: the input matrix \n",
    "    # n: the index (corresponds to the column of U)\n",
    "    N = A.ndim\n",
    "    sizeA = np.array(A.shape)\n",
    "    sizeU = np.array(U.shape)\n",
    "    \n",
    "    sizeB = np.delete(sizeA,n)\n",
    "    sizeB = np.insert(sizeB,0,sizeU[0])\n",
    "    A_mat = tenmat(A,n)\n",
    "    B = np.matmul(U,A_mat)\n",
    "    B = np.reshape(B,sizeB)\n",
    "    perm = np.arange(N)\n",
    "    perm = np.delete(perm,0)\n",
    "    perm = np.insert(perm,n,0)\n",
    "    B = np.transpose(B,perm)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee76ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate a tensor times a series of matrices\n",
    "import numpy as np\n",
    "\n",
    "def ttmc(A,U_list,op_index,transpose=False):\n",
    "    # A: the input tensor\n",
    "    # U_list: the input vectors (contracting the column)\n",
    "    # op_index: the indices that need to be contracted (in tensor)\n",
    "    \n",
    "    B = np.array(A,copy=True)\n",
    "    for i in range(len(U_list)):\n",
    "        if transpose:\n",
    "            B = ttm(B,U_list[i].T,op_index[i])\n",
    "        else:\n",
    "            B = ttm(B,U_list[i],op_index[i])\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdedfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate the rank-r approximation of a matrix by alternating least squares method with fixed error tolerance\n",
    "import numpy as np\n",
    "\n",
    "def als2_1(A,r,init=\"random\",tol=1.0e-4,maxiter=500):\n",
    "    # A: the input matrix\n",
    "    # r: truncation\n",
    "    # init: initial factors\n",
    "    # tol: stop criterion\n",
    "    # maxiter: the maximum number of iterations\n",
    "    \n",
    "    normA = np.linalg.norm(A)\n",
    "    sizeA = A.shape\n",
    "    num_iter = 0\n",
    "    \n",
    "    # initial factor\n",
    "    if isinstance(init,np.ndarray):\n",
    "        U_list = []\n",
    "        U_list.append(init)\n",
    "        U_list.append(np.random.random([sizeA[1],r]))\n",
    "    elif init == \"random\":\n",
    "        U_list = []\n",
    "        U_list.append(np.random.random([sizeA[0],r]))\n",
    "        U_list.append(np.random.random([sizeA[1],r]))\n",
    "        \n",
    "    B = np.matmul(U_list[0],U_list[1].T)\n",
    "    res_old = np.linalg.norm(A - B)/normA\n",
    "    res_change = res_old\n",
    "    \n",
    "#     print(\"\\033[1;35;46mAlternating least squares method for matrix low-rank approximation:\\n\\033[0m\")\n",
    "    while (res_change > tol and num_iter < maxiter):\n",
    "        # update the right factor\n",
    "        Coe = np.matmul(U_list[0].T,U_list[0])\n",
    "        Coe = np.linalg.inv(Coe)\n",
    "        Coe = np.matmul(Coe,U_list[0].T)\n",
    "        Coe = np.matmul(Coe,A)\n",
    "        U_list[1] = Coe.T\n",
    "        \n",
    "        # update the left factor\n",
    "        Coe = np.matmul(U_list[1].T,U_list[1])\n",
    "        Coe = np.linalg.inv(Coe)\n",
    "        Coe = np.matmul(U_list[1],Coe)\n",
    "        Coe = np.matmul(A,Coe)\n",
    "        U_list[0] = Coe\n",
    "        \n",
    "        B = np.matmul(U_list[0],U_list[1].T)\n",
    "        res_new = np.linalg.norm(A - B)/normA\n",
    "        res_change = np.abs(res_new - res_old)\n",
    "        res_old = res_new\n",
    "        num_iter += 1\n",
    "        \n",
    "#         print(f\"{num_iter}th-iteration: residual is {res_old}, error change is {res_change}\\n\")\n",
    "    \n",
    "    Q,R = np.linalg.qr(U_list[0])\n",
    "    U_list[0] = Q;\n",
    "    info = {\"factors\": U_list, \"residual\": res_new, \"iter\": num_iter}\n",
    "    return info\n",
    "\n",
    "# unit test\n",
    "# m,n,r = 10,5,1\n",
    "# A = np.random.random([m,n])\n",
    "# # u = np.random.random([m,r])\n",
    "# # v = np.random.random([n,r])\n",
    "# # U_init = [u,v]\n",
    "# info = als2_1(A,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303afbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate the rank-r approximation of a matrix by alternating least squares method with fixed maximum number of iterations\n",
    "import numpy as np\n",
    "\n",
    "def als2_2(A,r,init=\"random\",maxiter=2):\n",
    "    # A: the input matrix\n",
    "    # r: truncation\n",
    "    # init: initial factors\n",
    "    # maxiter: the maximum number of iterations\n",
    "    \n",
    "    sizeA = A.shape\n",
    "    num_iter = 0\n",
    "    \n",
    "    # initial factor\n",
    "    if isinstance(init,np.ndarray):\n",
    "        U_list = []\n",
    "        U_list.append(init)\n",
    "        U_list.append(np.random.random([sizeA[1],r]))\n",
    "    elif init == \"random\":\n",
    "        U_list = []\n",
    "        U_list.append(np.random.random([sizeA[0],r]))\n",
    "        U_list.append(np.random.random([sizeA[1],r]))\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        # update the right factor\n",
    "        Coe = np.matmul(U_list[0].T,U_list[0])\n",
    "        Coe = np.linalg.inv(Coe)\n",
    "        Coe = np.matmul(Coe,U_list[0].T)\n",
    "        Coe = np.matmul(Coe,A)\n",
    "        U_list[1] = Coe.T\n",
    "        \n",
    "        # update the left factor\n",
    "        Coe = np.matmul(U_list[1].T,U_list[1])\n",
    "        Coe = np.linalg.inv(Coe)\n",
    "        Coe = np.matmul(U_list[1],Coe)\n",
    "        Coe = np.matmul(A,Coe)\n",
    "        U_list[0] = Coe\n",
    "        \n",
    "    Q,R = np.linalg.qr(U_list[0])\n",
    "    U_list[0] = Q\n",
    "    info = {\"factors\": U_list}\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47152ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uesd to calculate the low multilinear-rank approximation of a tensor by HOOI-ALS\n",
    "import numpy as np\n",
    "\n",
    "def hooi_als(A,rank,init=\"random\",als=1,tol=1.0e-4,maxiter=500):\n",
    "    # A: the input tensor\n",
    "    # rank: the truncation\n",
    "    # init: initial factors\n",
    "    # als: determine the als scheme\n",
    "    # maxiter: the maximum number of iterations\n",
    "    \n",
    "    N = A.ndim\n",
    "    sizeA = A.shape\n",
    "    op_index = np.arange(N)\n",
    "    normA = np.linalg.norm(A)\n",
    "    num_iter = 0\n",
    "    \n",
    "    # initial factors\n",
    "    if isinstance(init,list):\n",
    "        U_list = init\n",
    "    elif init == \"random\":\n",
    "        U_list = []\n",
    "        for n in range(N):\n",
    "            U_list.append(np.random.random([sizeA[n],rank[n]]))\n",
    "            Q,R = np.linalg.qr(U_list[n])\n",
    "            U_list[n] = Q\n",
    "    \n",
    "    res_old = 1.0\n",
    "    res_change = 1.0\n",
    "    print(\"\\033[1;35;46mALS-based high-order orthogonal iteration:\\n\\033[0m\")\n",
    "    \n",
    "    while (res_change > tol and num_iter < maxiter):\n",
    "        for n in range(N):\n",
    "            inter_init = U_list[n]\n",
    "            op_interindex = np.delete(op_index,n)\n",
    "            U_list.pop(n)\n",
    "            B = ttmc(A,U_list,op_interindex,transpose=True)\n",
    "            mat = tenmat(B,n)\n",
    "            if als == 1:\n",
    "                info = als2_1(mat,rank[n],inter_init)\n",
    "            elif als == 2:\n",
    "                info = als2_2(mat,rank[n],inter_init)\n",
    "            U = info[\"factors\"]\n",
    "            U_list.insert(n,U[0])\n",
    "                \n",
    "        G = ttmc(A,U_list,op_index,transpose=True)\n",
    "        normG = np.linalg.norm(G)\n",
    "        res_new = np.sqrt(np.abs(1 - np.square(normG)/np.square(normA)))\n",
    "        res_change = np.abs(res_new - res_old)\n",
    "        res_old = res_new\n",
    "        num_iter += 1\n",
    "        \n",
    "        print(f\"{num_iter}th-iteration: residual is {res_new}, error change is {res_change}\")\n",
    "    \n",
    "    info = {\"core tensor\": G, \"factors\": U_list, \"residual\": res_new, \"iter\": num_iter}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52cff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35;46mALS-based high-order orthogonal iteration:\n",
      "\u001b[0m\n",
      "1th-iteration: residual is 0.49995919437223635, error change is 0.5000408056277637\n",
      "2th-iteration: residual is 0.49994634320135894, error change is 1.2851170877403728e-05\n",
      "TensorLy: residual is 0.4999348400404276\n",
      "\n",
      "ALS-based HOOI: 5.816516160964966s, TensorLy: 16.68782615661621s\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "from tensorly.decomposition import tucker\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# I,J,K,L,M = 10,10,100,100,100\n",
    "# A = np.random.random([I,J,K,L,M])\n",
    "# # A = np.empty([I,J,K,L,M])\n",
    "# # for i in range(I):\n",
    "# #     for j in range(J):\n",
    "# #         for k in range(K):\n",
    "# #             for l in range(L):\n",
    "# #                 for m in range(M):\n",
    "# #                     A[i,j,k,l,m] = np.sin(i+j+k+m+l)\n",
    "# rank = [2,2,2,2,2]\n",
    "\n",
    "# I,J,K = 100,1000,500\n",
    "# A = np.random.random([I,J,K])\n",
    "# rank = [10,10,50]\n",
    "\n",
    "I,J,K = 200,2000,500\n",
    "# A = np.empty([I,J,K])\n",
    "# for i in range(I):\n",
    "#     for j in range(J):\n",
    "#         for k in range(K):\n",
    "#             A[i,j,k] = np.sin(i+j+k)\n",
    "# A = np.random.normal(size=(I,J,K))\n",
    "A = np.random.random([I,J,K])\n",
    "rank = [20,10,10]\n",
    "\n",
    "time_start = time.time()\n",
    "info = hooi_als(A,rank,als=1)\n",
    "time_end = time.time()\n",
    "t1 = time_end - time_start\n",
    "\n",
    "time_start = time.time()\n",
    "core,factor = tucker(A,rank=rank)\n",
    "time_end = time.time()\n",
    "t2 = time_end - time_start\n",
    "normA = np.linalg.norm(A)\n",
    "normG = np.linalg.norm(core)\n",
    "residual = np.sqrt(np.abs(1 - np.square(normG)/np.square(normA)))\n",
    "\n",
    "print(f\"TensorLy: residual is {residual}\\n\")\n",
    "print(f\"ALS-based HOOI: {t1}s, TensorLy: {t2}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad7e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
